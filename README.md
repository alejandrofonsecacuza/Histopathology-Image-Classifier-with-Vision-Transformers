
# Histopathology Image Classifier with Vision Transformers (ViT)

Este proyecto implementa un sistema de **clasificaciÃ³n automÃ¡tica de imÃ¡genes histopatolÃ³gicas** utilizando **Vision Transformers (ViT)**.  
El objetivo es explorar el potencial de los *Transformers* en el anÃ¡lisis de imÃ¡genes mÃ©dicas, superando los enfoques tradicionales basados en CNN.

## âœ¨ CaracterÃ­sticas principales
- Uso de **Vision Transformer (ViT)** preentrenado como backbone.
- **Transfer Learning & Fine-Tuning** para ajustar el modelo a las clases especÃ­ficas.
- **Data Augmentation** estratificado para mejorar la generalizaciÃ³n.
- **EvaluaciÃ³n con mÃ©tricas estÃ¡ndar** (accuracy, precision, recall, F1-score).
- **Explainable AI (XAI)** mediante tÃ©cnicas de visualizaciÃ³n de atenciÃ³n.
- Implementado en **PyTorch**.

## ğŸ“Š Dataset
El conjunto de datos utilizado estÃ¡ disponible pÃºblicamente en [Figshare](https://figshare.com/articles/dataset/A_histopathological_image_dataset_for_endometrial_disease_diagnosis/7306361).  
Contiene **3300 imÃ¡genes histopatolÃ³gicas** clasificadas en 4 categorÃ­as principales:

- `NE`: Endometrio Normal  
- `EA`: Adenocarcinoma Endometrioide  
- `EP`: PÃ³lipo Endometrial  
- `EH`: Hiperplasia Endometrial  

> âš ï¸ El dataset **no se incluye directamente en este repositorio** por temas de licencia y tamaÃ±o. Debes descargarlo manualmente.

## ğŸ› ï¸ InstalaciÃ³n
Clona el repositorio y crea un entorno virtual:

```bash
git clone https://github.com/usuario/histopathology-vit.git
cd histopathology-vit

python -m venv venv
source venv/bin/activate   # Linux/Mac
venv\Scripts\activate      # Windows

pip install -r requirements.txt
````

## â–¶ï¸ Entrenamiento del modelo

```bash
python train.py --data_path ./dataset --epochs 10 --batch_size 32 --lr 3e-5
```

## ğŸ“ˆ Resultados

El modelo alcanzÃ³ una **accuracy del 80.28%** en el conjunto de prueba, superando a modelos CNN tradicionales en este dataset.

Ejemplo de matriz de confusiÃ³n:
![Confusion Matrix](docs/confusion_matrix.png)

Ejemplo de mapa de atenciÃ³n del ViT (XAI):
![Attention Map](docs/attention_map.png)


```

## ğŸ“š TecnologÃ­as

* [PyTorch](https://pytorch.org/)
* [Timm](https://github.com/huggingface/pytorch-image-models)
* [Scikit-learn](https://scikit-learn.org/)
* [Matplotlib / Seaborn](https://matplotlib.org/) 

## ğŸš€ PrÃ³ximos pasos

* Ampliar el dataset con nuevas muestras.
* Optimizar hiperparÃ¡metros y explorar arquitecturas hÃ­bridas.
* Integrar interpretabilidad avanzada con Grad-CAM y Attention Rollout.


